{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27448e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize spark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7605ab5-07af-4e59-a6b2-a0166385c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.feature import StopWordsRemover, Word2Vec, Tokenizer\n",
    "#from pyspark.ml.feature import RegexTokenizer,StopWordsRemover,CountVectorizer,IDF, HashingTF\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from  pyspark.ml.pipeline import PipelineModel  # For saving the model\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "# import structType\n",
    "from pyspark.sql.types import StructType, StringType\n",
    "from pyspark.sql.functions import from_json\n",
    "import numpy as np\n",
    "import requests\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb883a-c88d-47a3-b68e-1e60a80157fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff72aacf-00e4-4d93-9b4e-4512f07fd8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/Users/JoeKifle/spark-3.2.1-bin-hadoop3.2/sbin/start-master.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6be175-a962-4eec-86fb-5a34f536d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/Users/JoeKifle/spark-3.2.1-bin-hadoop3.2/sbin/start-worker.sh spark://joetelila.lan:7077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309c66d-25b7-47f0-b404-878681ab4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/Users/JoeKifle/spark-3.2.1-bin-hadoop3.2/sbin/stop-worker.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f129f42-f3ec-4304-8df2-e65c26eecc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/Users/JoeKifle/spark-3.2.1-bin-hadoop3.2/sbin/stop-master.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232f8e9-0bfd-40fb-9912-459770b72fff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency for spark-sql-kafka\n",
    "conf = pyspark.SparkConf()\n",
    "conf.set(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1\")\n",
    "\n",
    "#spark_master = \"spark://131.114.50.200:7077\"\n",
    "spark_master = \"spark://joetelila.lan:7077\"\n",
    "#sc = pyspark.SparkContext(master=spark_master,appName=\"Hello Spark\")\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(spark_master)\\\n",
    "        .appName(\"sentimentAnalysis\")\\\n",
    "        .config(conf=conf)\\\n",
    "        .getOrCreate()\n",
    "#spark._sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c05f9f-9d50-4cfa-887a-98112b29e4f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da860524-7187-4b5f-af04-4bb66e146c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the schema\n",
    "my_schema = tp.StructType([\n",
    "  tp.StructField(name= 'text',       dataType= tp.StringType(),   nullable= True),\n",
    "  tp.StructField(name= 'polarity',    dataType= tp.IntegerType(),  nullable= True)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5fbbb1-a6dc-4eaf-95a8-158c5bb54fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset  \n",
    "tweet_data = spark.read.csv('data/tweets_dataset_may6_no_comma.csv',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f37d01-2025-4b8b-b72b-149941927fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing handles and links from the tweets\n",
    "tweet_data = tweet_data.withColumn('text', F.regexp_replace('text','@[A-Za-z0-9_]+',''))\n",
    "tweet_data = tweet_data.withColumn('text', F.regexp_replace('text','https?://[^ ]+',''))\n",
    "tweet_data = tweet_data.withColumn('text', F.regexp_replace('text','www.[^ ]+',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a1b2c-587c-416f-b0ed-4b49f909163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the schema of the file\n",
    "tweet_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7e373-624d-44f0-8536-b107f9f2264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping null columns\n",
    "tweet_data=tweet_data.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dff17-f965-4698-a5a0-c4d46e4c9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of the polarity\n",
    "tweet_data.groupBy(\"polarity\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a2f757-cd8e-4438-8cf9-85c2bd65e304",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Building pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff2b14-56bc-4280-b417-77dc7ba43fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stages For the Pipeline\n",
    "tokenizer = Tokenizer(inputCol='text',outputCol='mytokens')\n",
    "stopwords_remover = StopWordsRemover(inputCol='mytokens',outputCol='filtered_tokens')\n",
    "word_2_vec = Word2Vec(inputCol= 'filtered_tokens', outputCol= 'w2v', vectorSize=200) #, vectorSize= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7122fa4d-43a5-4c9c-aa01-baa877e334f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LogisticRegression(featuresCol='vector',labelCol='polarity')\n",
    "model = LogisticRegression(featuresCol= 'w2v',labelCol= 'polarity', regParam=0.008, maxIter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf85d4-558b-42c8-9d52-846f12c58afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the pipeline\n",
    "pipeline = Pipeline(stages= [tokenizer, stopwords_remover, word_2_vec, model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e993f6-4d4b-412e-993a-587b78e936d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef2b4d-932e-44eb-8e00-7d26c23385cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split Dataset and train\n",
    "(train_tweet,test_tweet) = tweet_data.randomSplit((0.8,0.2),seed=42)\n",
    "pipelineFit = pipeline.fit(train_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b16fb1-1479-4f1e-a21c-0aaf79e37c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# fit the pipeline model with the training data\n",
    "if os.path.isdir('pipeline_model'):\n",
    "    # Loading the model\n",
    "    print(\"Loading the model from a file . . .\")\n",
    "    pipeline_model = PipelineModel.load('pipeline_model')\n",
    "else:\n",
    "    print(\"Training the model model . . .\")\n",
    "    pipelineFit = pipeline.fit(train_tweet)\n",
    "    # Persist the model, ref: https://spark.apache.org/docs/latest/ml-pipeline.html\n",
    "    pipelineFit.write().overwrite().save('pipeline_model')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299c395d-cc02-4ff8-96b2-91371cb79719",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2c1b9d-0183-4578-8a93-4798cda840c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on our - Test Dataset.\n",
    "predictions = pipelineFit.transform(test_tweet)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='polarity',predictionCol='prediction',metricName='f1')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcde62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persisting the model\n",
    "pipelineFit.write().overwrite().save('pipeline_lr_model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d105ada02192d0bbdad0d4b7f9e51b851ebd5be727b9bab0a9679568b88653"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pyspark_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
